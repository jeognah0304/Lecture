어떤정보를가져와야 y에 대한 리서치가 될까?

x 변수설정 -> 그리고 어디서 끌어와야할까 하는 대상기관을 체크함.p11
만약 국토교통부에서 데이터가 다 있냐? 없을수있어(신고한경우만있거든)
->만ㅎ은데이터가 빠져있다.

일자리에 관한 정보가 뭐가있을까? 실업금여의 사유(임금체급,실업....)


=> 데이터를 어떻게 연계해야하는지가 하나의 이슈임*(자살한 모녀가 자살데이터에 포함되있음)



데이터가 한꺼번에 추가된게 아니라, 작업하면서 하나하나 늘려나간 정보들임


p13. 등록장애인에 대한 정보도 다 같이 활용해서 연계정보를 만듦.
암호화된 주민등록번호로 연계를 시키는데, 주민번호가 없는 데이터가 있음
(정확하게 매칭못되서 버리는 데이터도 많고, 모든 데이터가 제대로 매칭이 되지 않음. 자살데이터도 그러함)
=> 그래도 한 70% 이상의 데이터를 씀.

=> 예측하고, 발굴대상자 업로드->그 사람 누군지 체크
=> 그리고 그 쌓인 결과들이 모형 구축에 사용됨.

=> 모형측면에서 살펴보고
각각 모형들을 구축해서, 그 두개의 모형중에 어떤 모형이 더 나은지를 판단 평가
*********************************************

분석에 사용되는 정보는 일부임.
단전이라해도 몇월부터 몇월까지 단전이 나오는데
그 기간동안의 금액도 나옴. 금액의 정보도 씀.
등등 많은 변수들이 있는데, 그걸 다 시스템 안에 가지고있음




** Predictive Modeling.



데이터가 없어서 하나의 모형만 가기가 어렵기에 다 써봄
> 점점 데이터가 쌓이고 하다보니, 어떤 모형이 예측력이 높은지 어느정도는 알 수 있음.
( 물론 더 나은 모형 있을수도 있지만, 리스크가 있으니까...^^)

설명력과 예측력에 어디에 포커스 맞춤!
(선택에 고민해야함)

->예측해서 하는데, 이 네가지 모형ㅇ르 쓴 이유???


로지스틱의 단점: 교호작용 TERM을 내가 넣어야함.
랜덤포레스트나, 부스팅은 교호작용 부부녿 알아서 고려해줌. 

엘라스틱넷은 다중공선성 문제를 해결하기 위해 넣어주고.
모형해석 쉽고. 변수선택도 가능함.

단! 파라메터 튜닝하는데 좀 어려움이있다 정도?



랜덤포레스트 ->이상치에 둔감해서 로버스트함.
BOOSTING이 예측력이 높고, 로버스트한데 파라메터 튜닝이 어려움.



네가지 결과값을 리포트해서 다 사용했는데.
결국 부스팅으로만 썼고, 그 중에 패키지 중 XGBoost 씀.
=> 예측력이 높다? training set으로 데이터 구축하고 test set으로 평가하잖아요
->그래서 비교판단함.



데이터감ㄶ아질수록 모형이 안정화됨
->범죄피해자여부의ㅓ 정보가 오는데,
-> 적은 숫자에 대한 직접 현장조사시 매우 작은 숫자가 됨
(그거조심해야함)

그래서 데이터 크기가 커질수록 모형이 안정화됨.

로지스틱이 양의 방향인지 음의 방향인지 설명이 도ㅣ는뎅


y = 0,1로 코딩이 된 상황. 1은 도움이 필요한 사람. 0은 그렇지 안흔 사람.
근데 이거 보면서, 정보가 0에 가까운 계수면 응....??? 그정보 왜 써? 누가 써야해??

내가 모은 정보가 다 양의 방향이 나와야 한다고 생각을 해야함.
그래서 근데 결과를 보니까 그렇지 않았음
연금보험을 그냥 안내는 사람들도 잇어. 그게 꼭 어려워서 안내는 경우가 있음.
속성이 다를 수가 있어서. 그래서 그 음수값인데, 이 정보를 계속 가지고 와야하나
회의를 몇달함.

=> boosting결과를 보면, 상대적 영향도가 있는데
각 변수들을 가지고, 그 전체 막대의 길이의 합이 100%가 되구여.
각 변수에 대한 상대적 영향도에여. =>다 합치면 100이되는건데.

여기서 영향력은, 0으로 갈꺼냐 1로 갈꺼냐의 편가르기인데.
그래서 그 결가값을 그대로 가져갈 생각을함.






*************정부요청.
아동들도 데이터 이용해서 찾아낼 수 없냐??


모이는 데이터 속성이 다 다르기때문에,
사진지원파트,예방파트가 있어ㅇㅑ함.


조기발견하는데 모델링 관여 하나.
사후지원 : 재학대 발생 막기위한 사후관리도 함.




발굴대상자 >내려보낸 숫자임.

중간중간이ㅡ 데이터의 한계까 있음.





데이터에서 유의하다고 생각하는 변수, 지자체 일선회 등.
유의하다고 생ㄷ각하는 변수가 괴리가 있음.


신용정보는 법때매 연계까 안되었음.
그게 막판에 연계가 되서 넣음*

모형고도화는 계속 이루어져야함.
모델 고도화작업을 계ㅔ에에속 해야함.
튜닝할게 많음



신청했었어야하면, 찾아주는 복지로 감.




1.고민:예측력이 높은모형쓸래, 설명력이 높은 모형?
2. 연계정보가 복지사각지대의 정의할때 개인과 가구 표현했는데,
그 데이터셋을 구성할때 350만명(개인으로). 개인속성,가구속성 정보가 있을수있음.
자살시도 이런건 개인정보. .... 가구정보....
변수마다 개인의 속성과 가구의 속성이 있는게 섞여있음.
그부분 고민**

3. 연금보험료 체납. 빼실건지, ... -> 같이 고민하고 했지.
음수 나온 coefficent....

마케팅 경영학에선, 빼더라. 근데 모형의 정확도를 넣어서.
모형ㅇ로 얘기하는게 빼지않고 가는게 낫겟다고 함.
논의끝에 연금보험료 체납...

빼라고한이유?
이런저런 자료 끌어모으잖아요. 너무많은 정보를 가지고옴.
감사원 지적사항. 복지사각지대발굴에 진짜 다 써?
1이아니라 0인 맞춰야한다... 그니까 필요한 업무의ㅓ 효율성도 관련되어있음.

350만명.
10만명 0> 상위 5만명만 뽑음. 그렇게 했을때 실제 0이나온 사람들은
정부의 공적지원, 민간지원으로 나누는데. 민간지원은 동사무소마다
그런 업체랑 연계해서 라면ㅁ한박스 주고 그런거. ...
발굴실적 -> 시스템 안에서 25%비율에서. 

활유된 데이터로 -> 모델고도화 -> 그게 적절한가?
한쪽에만 너무 편향된 정보가 있을수있어서 bias를 없애보자.

그래서 중간중간에 음수가 된 정보.
연금보험료 이거 그렇거든ㄷ..

근데 화재피해여부대상자는 한번 봐볼만 하거든(이것도 음수야)
이거 전수 다 내려보기도 함. 많지도않거든.
범죄피해여부 이런거 많지않아.

다 작업들을 할 수 있었음.
자살시도 경험도 음수가 되는데...
그럼 ㅁ이게 진짜 음수냐??? 이런거 확인해봐야함.
이러한 특성들이, 상위 사람들의 사람만 가지고 내려보는거라
이런 특성이반영될까가 정말 문제가 되지 않는지,
통계적으로. 수식적으로 문제가되지않는지고미ㄴ냈는뎅.
(크게 문제안된다 결론 ) = >그런 부분이 고민 포인트.






**********************************************
테스트셋에서 0,1 짤라서 내려보내야함
2015.12월 데이터셋. 트레이닝셋 없으면....
실제조사함!!(트레이닝셋을 실제조사로 대처함)


그리고 y =0,1은 실제있는 데이터가 아니야! 조심해야해!!
0은 신청했다가 떨어진 사람들.실제 조사를 할려면

단전된경험, 단수된 경험 알아보는게 쉬웠을까?
속성정보들. 지난 일년간 복지혜택. 서비스를 받기 전에 시점을 알아봐야했기 때문에
대상자들을 지난 일년간 받기전의 상황이어서 단전된 경험이있는지
단수된 경험이있는지. 자살시도 경험 등등의 변수로 활용을 했었던
체납된 경험이 있는지, 다 정보를 변수화해서 만들어놨었음.

그 ㄷ ㅔ이터 가지고 모형을 만들었고 0,1이 명확히 있잖아요.
트레이닝셋이 y값 없는거구.

모형의 평가를 하기위함이라면 실제 y값이 다 ㅇ ㅣㅆ는 랜덤하게 80, 20 쪼개서
y값이 없다고 생각하고 비교를 함....


350만명은 다 테스트셋이었음!!!!!!!!!!!!!
조사를 했었음 ->

0,1 지원을 받고있는 사람이 더 많았음. 1의 비율이 85%. 0의비율이 15% 이었음.

근데 실제로는?
350만명중에 10만명을 뽑아서 내려보냈을때, 1의 비율은 25% 75% 인 데이터셋이 나와서
활류데이터 셋이 중요하다고 강조한 이유가 여기에 잇었음.


모형구축을 계속 함
=-> 모든정보가 처음부터 쌓인게 ㅏ니라 중간중간에 들어옴.

신용정보같은 경우에는 뒤늦게 들어옴.(근데 그러면 코이피션트 추가되서 안되..)
트레이닝셋에 그 정보!!!












---------------첫시간-----------------------



4차산업혁명 - digital.


빅데이터 보면 인터넷 데이터 가져오잖아요? 나이가 50-60대가없으니
모집단대표성이 낮져.




***
N : 3500000
N 1700

오차한계량 다 고민하고, 지역도 다 고민하고..
1300이 나오는데
그럼 적정 표본은 얼마일지 고민해보자!






-------------------------------------------------------------------------

빅데이터** P11
예측넘어서 사후적인 예방책까지도 넘어갔다 Prescriptive






AI안에 기계학습.
그리고 그 안에 딥러닝, 




학습데이터에서
y가 미리 있다하면 지도핛브
없으면 비지도학습.



분류, ㅇ





카이스트 머신러닝 튜토리얼.
단어를 벡터화해서 단어와 단어간의 (텍스트마이닝쪽) 거리를 연산하게끔
그런 기법을 개발(딥러닝기반)

-> 
텍스트마이닝.
단어와 단어사이의 더하기빼기가 가능함
-> 실제 삼성+스마트폰 = 갤럭시.
이런식의 연산이 나옴. 그러면 삼성-스마트폰 (반도체)= 제일모직,삼성물산...

단어와 단어사이의 더하기 빼기가 가능.

대한민국+서울+도쿄 = 일본.


텍스트마이닝의 한계점*
다 단어를 쪼개는데, 근데 그거도 요즘 보완가능
(이름. 트럼프 이런거..)




맛집평가
문장 안에서 플러스 마이너스에 대한 그림도 나오고
맛집에 대한 평가도 수치화되서 다 표현이 됨.




p-value랑
가설을 보고
가설을 제대로 검정할 수 있는지를 잘 봐야함

데이터가 적합한건지를 봐라는 것임.

** 샘플사이즈가 커지면 p-value가 커지는게 당연한거니까
그걸 항상 조심해야함.

** p-value
통ㄷ계적 유의성과 효과의 크기나 결과의 중요성을 나타내지 않음.


성명서 읽어보기



https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108 